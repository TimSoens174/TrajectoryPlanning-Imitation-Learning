# TrajectoryPlanning-Imitation-Learning
Reinforcement Learning in urban enviroment using the carla simulator and imitation learning

This project explores the use of Reinforcement Learning (RL) to enable an autonomous vehicle to navigate urban environments inside the CARLA simulator.
To achieve stable and realistic driving behavior, the agent first learns through Imitation Learning, using trajectories generated by a Frenet Planner, and later improves its performance through RL.

## Project Goal

The goal is to train a vehicle to drive safely, efficiently, and smoothly in complex urban scenarios involving:

Dynamic traffic participants (cars, cyclists, pedestrians)

Intersections and traffic lights

Pedestrian crossings

Speed limits

Curved roads and lane geometries

## Frenet Planner – Demonstration

The following GIF shows the reference trajectories generated by the Frenet Planner, which are used as demonstration data in the Imitation Learning stage:

![Frenet Planner Demo](frenet_planner.gif)

## Approach

The project starts by imitating a Frenet Planner, a trajectory generation method widely used in autonomous driving.
The planner provides high-quality reference trajectories based on:

Lane information

Road curvature

Speed profiles

The agent learns to follow these trajectories using three key control parameters that quantify how closely the simulated vehicle follows the planner:

Steering angle

Lateral distance to the reference path

Speed difference

This allows the agent to match the planner’s behavior before moving on to more complex RL tasks.

## Results – Demonstration

The following GIF shows the trained RL agent driving inside CARLA and executing learned behaviors:

![RL Results Demo](S-Curve.gif)
